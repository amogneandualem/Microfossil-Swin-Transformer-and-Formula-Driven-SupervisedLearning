{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1339633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"Is CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Current device name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911863f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"‚úÖ All imports completed successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218426ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd73376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.data_path = \"/aifs/user/home/amogneandualem/Microfossil Classification/All_dataset\"\n",
    "        self.model_paths = {\n",
    "            'exfractal': \"/aifs/user/home/amogneandualem/Microfossil Classification/Pre traiened models/exfractal_21k_base.pth.tar\",\n",
    "            'imagenet': \"/aifs/user/home/amogneandualem/Microfossil Classification/Pre traiened models/imagenet_21k_base.pth.tar\", \n",
    "            'rcdb': \"/aifs/user/home/amogneandualem/Microfossil Classification/Pre traiened models/rcdb_21k_base.pth.tar\"\n",
    "        }\n",
    "        self.results_path = \"/aifs/user/home/amogneandualem/Microfossil Classification/results\"\n",
    "        self.image_size = (224, 224)\n",
    "        self.batch_size = 32\n",
    "        self.num_workers = 4\n",
    "        self.num_classes = 32\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.num_epochs = 40\n",
    "        \n",
    "config = Config()\n",
    "\n",
    "# Create results directory\n",
    "Path(config.results_path).mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Results will be saved to: {config.results_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c07eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Dataset Analysis and Class Mapping\n",
    "print(\"=\" * 70)\n",
    "print(\"PHASE 1: DATASET ANALYSIS AND CLASS MAPPING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "class DatasetAnalyzer:\n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "        self.class_counts = {}\n",
    "        self.class_mapping = {}\n",
    "        self.reverse_mapping = {}\n",
    "        \n",
    "    def analyze_dataset(self):\n",
    "        \"\"\"Analyze dataset structure and create class mappings\"\"\"\n",
    "        if not os.path.exists(self.data_path):\n",
    "            print(f\"‚ùå Data path {self.data_path} does not exist!\")\n",
    "            return None\n",
    "            \n",
    "        # Check if data is already split or needs splitting\n",
    "        if os.path.exists(os.path.join(self.data_path, 'train')):\n",
    "            print(\"üìÅ Found pre-split dataset (train/val/test structure)\")\n",
    "            split_dirs = ['train', 'val', 'test']\n",
    "        else:\n",
    "            print(\"üìÅ Found unsplit dataset - will create splits\")\n",
    "            split_dirs = ['']\n",
    "        \n",
    "        # Get all classes\n",
    "        all_classes = set()\n",
    "        for split_dir in split_dirs:\n",
    "            split_path = os.path.join(self.data_path, split_dir) if split_dir else self.data_path\n",
    "            if os.path.exists(split_path):\n",
    "                classes = [d for d in os.listdir(split_path) \n",
    "                          if os.path.isdir(os.path.join(split_path, d))]\n",
    "                all_classes.update(classes)\n",
    "        \n",
    "        # Create class mapping\n",
    "        self.classes = sorted(list(all_classes))\n",
    "        self.class_mapping = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        self.reverse_mapping = {idx: cls for cls, idx in self.class_mapping.items()}\n",
    "        \n",
    "        print(f\"üéØ Found {len(self.classes)} classes:\")\n",
    "        for i, cls in enumerate(self.classes):\n",
    "            print(f\"   {i:2d}. {cls}\")\n",
    "        \n",
    "        # Count images per class\n",
    "        total_images = 0\n",
    "        for cls in self.classes:\n",
    "            class_count = 0\n",
    "            for split_dir in split_dirs:\n",
    "                split_path = os.path.join(self.data_path, split_dir) if split_dir else self.data_path\n",
    "                class_path = os.path.join(split_path, cls)\n",
    "                if os.path.exists(class_path):\n",
    "                    images = [f for f in os.listdir(class_path) \n",
    "                             if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]\n",
    "                    class_count += len(images)\n",
    "            self.class_counts[cls] = class_count\n",
    "            total_images += class_count\n",
    "        \n",
    "        return self.class_counts, self.class_mapping\n",
    "    \n",
    "    def plot_class_distribution(self):\n",
    "        \"\"\"Plot class distribution\"\"\"\n",
    "        classes = list(self.class_counts.keys())\n",
    "        counts = list(self.class_counts.values())\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 6))\n",
    "        \n",
    "        # Bar plot\n",
    "        ax1.bar(range(len(classes)), counts, color='skyblue', alpha=0.7)\n",
    "        ax1.set_title('SO32 Dataset - Class Distribution', fontsize=14, fontweight='bold')\n",
    "        ax1.set_xlabel('Class Index')\n",
    "        ax1.set_ylabel('Number of Images')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Statistics table\n",
    "        stats_data = [\n",
    "            ['Total Images', sum(counts)],\n",
    "            ['Total Classes', len(classes)],\n",
    "            ['Average per Class', f\"{np.mean(counts):.1f}\"],\n",
    "            ['Max per Class', max(counts)],\n",
    "            ['Min per Class', min(counts)],\n",
    "            ['Classes < 100', len([c for c in counts if c < 100])],\n",
    "            ['Classes < 50', len([c for c in counts if c < 50])],\n",
    "            ['Classes < 10', len([c for c in counts if c < 10])]\n",
    "        ]\n",
    "        \n",
    "        table = ax2.table(cellText=stats_data, \n",
    "                         cellLoc='center', \n",
    "                         loc='center',\n",
    "                         colWidths=[0.4, 0.2])\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(12)\n",
    "        table.scale(1, 2)\n",
    "        ax2.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print detailed statistics\n",
    "        print(f\"\\nüìä DATASET STATISTICS:\")\n",
    "        print(f\"   Total images: {sum(counts)}\")\n",
    "        print(f\"   Total classes: {len(classes)}\")\n",
    "        print(f\"   Average images per class: {np.mean(counts):.1f}\")\n",
    "        print(f\"   Max images in class: {max(counts)}\")\n",
    "        print(f\"   Min images in class: {min(counts)}\")\n",
    "        print(f\"   Standard deviation: {np.std(counts):.1f}\")\n",
    "\n",
    "# Analyze dataset\n",
    "analyzer = DatasetAnalyzer(config.data_path)\n",
    "class_counts, class_mapping = analyzer.analyze_dataset()\n",
    "\n",
    "if class_counts:\n",
    "    analyzer.plot_class_distribution()\n",
    "    \n",
    "    # Save class mapping\n",
    "    with open(f'{config.results_path}/class_mapping.json', 'w') as f:\n",
    "        json.dump({'class_to_idx': analyzer.class_mapping, 'idx_to_class': analyzer.reverse_mapping}, f, indent=2)\n",
    "    print(f\"üíæ Class mapping saved to: {config.results_path}/class_mapping.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b49e42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Dataset Analysis with Original Paper Strategy\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PHASE 2: DATASET ANALYSIS WITH PAPER-COMPLIANT STRATEGY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class PaperCompliantDatasetAnalyzer:\n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "        self.class_counts = {}\n",
    "        self.class_mapping = {}\n",
    "        self.reverse_mapping = {}\n",
    "        \n",
    "    def analyze_with_paper_strategy(self, max_per_class=1000):\n",
    "        \"\"\"Analyze dataset using the original paper's strategy\"\"\"\n",
    "        print(\"üìä Analyzing dataset with paper-compliant strategy...\")\n",
    "        print(f\"   Maximum images per class: {max_per_class} (as per original paper)\")\n",
    "        \n",
    "        classes = [d for d in os.listdir(self.data_path) \n",
    "                  if os.path.isdir(os.path.join(self.data_path, d))]\n",
    "        \n",
    "        self.classes = sorted(classes)\n",
    "        self.class_mapping = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        self.reverse_mapping = {idx: cls for cls, idx in self.class_mapping.items()}\n",
    "        \n",
    "        total_original = 0\n",
    "        total_after_limiting = 0\n",
    "        \n",
    "        print(f\"\\nüéØ Found {len(self.classes)} classes:\")\n",
    "        \n",
    "        for class_name in self.classes:\n",
    "            class_path = os.path.join(self.data_path, class_name)\n",
    "            images = [f for f in os.listdir(class_path) \n",
    "                     if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]\n",
    "            \n",
    "            original_count = len(images)\n",
    "            total_original += original_count\n",
    "            \n",
    "            # Apply paper's strategy: limit to max_per_class for large classes\n",
    "            if original_count > max_per_class:\n",
    "                limited_count = max_per_class\n",
    "                status = f\"LIMITED to {max_per_class}\"\n",
    "            else:\n",
    "                limited_count = original_count\n",
    "                status = \"OK\"\n",
    "                \n",
    "            total_after_limiting += limited_count\n",
    "            self.class_counts[class_name] = limited_count\n",
    "            \n",
    "            print(f\"   {class_name:.<30} {original_count:>4} -> {limited_count:>4} {status}\")\n",
    "        \n",
    "        print(f\"\\nüìà DATASET SIZE ANALYSIS:\")\n",
    "        print(f\"   Original total images: {total_original}\")\n",
    "        print(f\"   After applying paper strategy: {total_after_limiting}\")\n",
    "        print(f\"   Reduction: {total_original - total_after_limiting} images ({((total_original - total_after_limiting)/total_original)*100:.1f}%)\")\n",
    "        \n",
    "        return self.class_counts, self.class_mapping\n",
    "    \n",
    "    def plot_paper_comparison(self, original_paper_size=53000):\n",
    "        \"\"\"Compare current dataset with original paper\"\"\"\n",
    "        current_total = sum(self.class_counts.values())\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 6))\n",
    "        \n",
    "        # Current vs Paper comparison\n",
    "        sizes = [current_total, original_paper_size]\n",
    "        labels = [f'Current Dataset\\n{current_total} images', f'Original Paper\\n{original_paper_size} images']\n",
    "        colors = ['lightblue', 'lightcoral']\n",
    "        \n",
    "        ax1.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "        ax1.set_title('Dataset Size Comparison', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Current class distribution\n",
    "        classes = list(self.class_counts.keys())\n",
    "        counts = list(self.class_counts.values())\n",
    "        \n",
    "        ax2.bar(range(len(classes)), counts, color='skyblue', alpha=0.7)\n",
    "        ax2.set_title('Current Dataset - Class Distribution (Limited to 1000 max)', fontsize=14, fontweight='bold')\n",
    "        ax2.set_xlabel('Class Index')\n",
    "        ax2.set_ylabel('Number of Images')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print detailed statistics\n",
    "        self._print_detailed_statistics(current_total, original_paper_size)\n",
    "    \n",
    "    def _print_detailed_statistics(self, current_total, original_paper_size):\n",
    "        \"\"\"Print detailed dataset statistics\"\"\"\n",
    "        counts = list(self.class_counts.values())\n",
    "        \n",
    "        print(f\"\\nüìä DETAILED STATISTICS:\")\n",
    "        print(f\"   Current dataset size: {current_total}\")\n",
    "        print(f\"   Original paper size: {original_paper_size}\")\n",
    "        print(f\"   Percentage of original: {(current_total/original_paper_size)*100:.1f}%\")\n",
    "        print(f\"   Number of classes: {len(self.class_counts)}\")\n",
    "        print(f\"   Average images per class: {np.mean(counts):.1f}\")\n",
    "        print(f\"   Standard deviation: {np.std(counts):.1f}\")\n",
    "        print(f\"   Max images in class: {max(counts)}\")\n",
    "        print(f\"   Min images in class: {min(counts)}\")\n",
    "        print(f\"   Classes at maximum (1000): {len([c for c in counts if c == 1000])}\")\n",
    "        print(f\"   Classes with < 100 images: {len([c for c in counts if c < 100])}\")\n",
    "        print(f\"   Classes with < 50 images: {len([c for c in counts if c < 50])}\")\n",
    "        print(f\"   Classes with < 10 images: {len([c for c in counts if c < 10])}\")\n",
    "\n",
    "# Analyze dataset with paper-compliant strategy\n",
    "analyzer = PaperCompliantDatasetAnalyzer(config.data_path)\n",
    "class_counts, class_mapping = analyzer.analyze_with_paper_strategy(max_per_class=1000)\n",
    "\n",
    "# Compare with original paper\n",
    "analyzer.plot_paper_comparison(original_paper_size=53000)\n",
    "\n",
    "# Save class mapping\n",
    "with open(f'{config.results_path}/class_mapping.json', 'w') as f:\n",
    "    json.dump({'class_to_idx': analyzer.class_mapping, 'idx_to_class': analyzer.reverse_mapping}, f, indent=2)\n",
    "print(f\"üíæ Class mapping saved to: {config.results_path}/class_mapping.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b196139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Strategic Data Splitting with Augmentation Planning\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PHASE 3: STRATEGIC DATA SPLITTING & AUGMENTATION PLANNING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class StrategicDataSplitter:\n",
    "    def __init__(self, data_path, output_path, class_mapping, class_counts, \n",
    "                 train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):\n",
    "        self.data_path = data_path\n",
    "        self.output_path = output_path\n",
    "        self.class_mapping = class_mapping\n",
    "        self.class_counts = class_counts\n",
    "        self.train_ratio = train_ratio\n",
    "        self.val_ratio = val_ratio\n",
    "        self.test_ratio = test_ratio\n",
    "        self.split_counts = {'train': {}, 'val': {}, 'test': {}}\n",
    "        self.augmentation_needs = {}\n",
    "        \n",
    "    def split_with_augmentation_planning(self):\n",
    "        \"\"\"Split dataset and calculate augmentation needs\"\"\"\n",
    "        print(\"üîÑ Splitting dataset with augmentation planning...\")\n",
    "        \n",
    "        # Create output directories\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            split_path = os.path.join(self.output_path, split)\n",
    "            Path(split_path).mkdir(parents=True, exist_ok=True)\n",
    "            for class_name in self.class_mapping.keys():\n",
    "                Path(os.path.join(split_path, class_name)).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        total_stats = {'before': {}, 'after': {}}\n",
    "        target_per_class = 1000  # Target after augmentation\n",
    "        \n",
    "        for class_name in self.class_mapping.keys():\n",
    "            class_path = os.path.join(self.data_path, class_name)\n",
    "            \n",
    "            if not os.path.exists(class_path):\n",
    "                print(f\"‚ö†Ô∏è  Class directory not found: {class_path}\")\n",
    "                continue\n",
    "                \n",
    "            images = [f for f in os.listdir(class_path) \n",
    "                     if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]\n",
    "            \n",
    "            # Apply paper's limiting strategy\n",
    "            available_images = min(len(images), self.class_counts[class_name])\n",
    "            images = random.sample(images, available_images) if len(images) > available_images else images\n",
    "            \n",
    "            total_stats['before'][class_name] = len(images)\n",
    "            \n",
    "            if len(images) == 0:\n",
    "                print(f\"‚ö†Ô∏è  No images available for class: {class_name}\")\n",
    "                continue\n",
    "            \n",
    "            # Split images\n",
    "            train_imgs, temp_imgs = train_test_split(\n",
    "                images, test_size=(self.val_ratio + self.test_ratio), random_state=42\n",
    "            )\n",
    "            \n",
    "            val_imgs, test_imgs = train_test_split(\n",
    "                temp_imgs, test_size=self.test_ratio/(self.val_ratio + self.test_ratio), \n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            # Store split counts\n",
    "            self.split_counts['train'][class_name] = len(train_imgs)\n",
    "            self.split_counts['val'][class_name] = len(val_imgs)\n",
    "            self.split_counts['test'][class_name] = len(test_imgs)\n",
    "            \n",
    "            # Calculate augmentation needs\n",
    "            current_train = len(train_imgs)\n",
    "            augmentation_needed = max(0, target_per_class - current_train)\n",
    "            \n",
    "            # Determine augmentation intensity based on current size\n",
    "            if current_train < 100:\n",
    "                augmentation_factor = 8  # Very aggressive\n",
    "                augmentation_type = \"VERY_AGGRESSIVE\"\n",
    "            elif current_train < 300:\n",
    "                augmentation_factor = 4  # Aggressive\n",
    "                augmentation_type = \"AGGRESSIVE\"\n",
    "            elif current_train < 600:\n",
    "                augmentation_factor = 2  # Moderate\n",
    "                augmentation_type = \"MODERATE\"\n",
    "            else:\n",
    "                augmentation_factor = 1  # Light\n",
    "                augmentation_type = \"LIGHT\"\n",
    "            \n",
    "            self.augmentation_needs[class_name] = {\n",
    "                'current': current_train,\n",
    "                'needed': augmentation_needed,\n",
    "                'target': min(target_per_class, current_train * augmentation_factor),\n",
    "                'factor': augmentation_factor,\n",
    "                'type': augmentation_type,\n",
    "                'can_reach_target': (current_train * augmentation_factor) >= target_per_class\n",
    "            }\n",
    "            \n",
    "            # Copy images (commented for demo)\n",
    "            # self._copy_images(class_name, train_imgs, 'train')\n",
    "            # self._copy_images(class_name, val_imgs, 'val')\n",
    "            # self._copy_images(class_name, test_imgs, 'test')\n",
    "            \n",
    "            print(f\"‚úÖ {class_name}: Train({len(train_imgs)}), AugNeed({augmentation_needed}), Type({augmentation_type})\")\n",
    "        \n",
    "        return total_stats, self.split_counts, self.augmentation_needs\n",
    "    \n",
    "    def plot_augmentation_strategy(self):\n",
    "        \"\"\"Plot comprehensive augmentation strategy\"\"\"\n",
    "        classes = list(self.augmentation_needs.keys())\n",
    "        current = [self.augmentation_needs[cls]['current'] for cls in classes]\n",
    "        needed = [self.augmentation_needs[cls]['needed'] for cls in classes]\n",
    "        targets = [self.augmentation_needs[cls]['target'] for cls in classes]\n",
    "        factors = [self.augmentation_needs[cls]['factor'] for cls in classes]\n",
    "        \n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20, 12))\n",
    "        \n",
    "        # Before and after augmentation\n",
    "        x = np.arange(len(classes))\n",
    "        width = 0.25\n",
    "        \n",
    "        ax1.bar(x - width, current, width, label='Current', color='lightblue', alpha=0.7)\n",
    "        ax1.bar(x, targets, width, label='After Augmentation', color='lightcoral', alpha=0.7)\n",
    "        ax1.bar(x + width, [1000] * len(classes), width, label='Target (1000)', color='lightgreen', alpha=0.7)\n",
    "        \n",
    "        ax1.set_xlabel('Classes')\n",
    "        ax1.set_ylabel('Number of Images')\n",
    "        ax1.set_title('Training Set: Current vs After Augmentation', fontsize=14, fontweight='bold')\n",
    "        ax1.legend()\n",
    "        ax1.tick_params(axis='x', rotation=45)\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Augmentation factors\n",
    "        colors = ['red' if f >= 8 else 'orange' if f >= 4 else 'yellow' if f >= 2 else 'green' for f in factors]\n",
    "        ax2.bar(classes, factors, color=colors, alpha=0.7)\n",
    "        ax2.set_xlabel('Classes')\n",
    "        ax2.set_ylabel('Augmentation Factor')\n",
    "        ax2.set_title('Augmentation Intensity by Class', fontsize=14, fontweight='bold')\n",
    "        ax2.tick_params(axis='x', rotation=45)\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Augmentation needs\n",
    "        ax3.bar(classes, needed, color='purple', alpha=0.7)\n",
    "        ax3.set_xlabel('Classes')\n",
    "        ax3.set_ylabel('Additional Images Needed')\n",
    "        ax3.set_title('Augmentation Requirements', fontsize=14, fontweight='bold')\n",
    "        ax3.tick_params(axis='x', rotation=45)\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Augmentation type distribution\n",
    "        aug_types = [self.augmentation_needs[cls]['type'] for cls in classes]\n",
    "        type_counts = {t: aug_types.count(t) for t in set(aug_types)}\n",
    "        \n",
    "        ax4.pie(type_counts.values(), labels=type_counts.keys(), autopct='%1.1f%%', startangle=90)\n",
    "        ax4.set_title('Augmentation Strategy Distribution', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        self._print_augmentation_statistics()\n",
    "    \n",
    "    def _print_augmentation_statistics(self):\n",
    "        \"\"\"Print detailed augmentation statistics\"\"\"\n",
    "        total_current = sum([self.augmentation_needs[cls]['current'] for cls in self.augmentation_needs])\n",
    "        total_after = sum([self.augmentation_needs[cls]['target'] for cls in self.augmentation_needs])\n",
    "        total_needed = sum([self.augmentation_needs[cls]['needed'] for cls in self.augmentation_needs])\n",
    "        \n",
    "        print(f\"\\nüìä AUGMENTATION STRATEGY STATISTICS:\")\n",
    "        print(f\"   Total current training images: {total_current}\")\n",
    "        print(f\"   Total after augmentation: {total_after}\")\n",
    "        print(f\"   Total augmentations needed: {total_needed}\")\n",
    "        print(f\"   Dataset size increase: {((total_after-total_current)/total_current)*100:.1f}%\")\n",
    "        \n",
    "        # Count by augmentation type\n",
    "        type_counts = {}\n",
    "        for cls in self.augmentation_needs:\n",
    "            aug_type = self.augmentation_needs[cls]['type']\n",
    "            type_counts[aug_type] = type_counts.get(aug_type, 0) + 1\n",
    "        \n",
    "        print(f\"\\n   Augmentation strategy breakdown:\")\n",
    "        for aug_type, count in type_counts.items():\n",
    "            percentage = (count / len(self.augmentation_needs)) * 100\n",
    "            print(f\"     - {aug_type}: {count} classes ({percentage:.1f}%)\")\n",
    "        \n",
    "        # Classes that can reach target\n",
    "        can_reach = len([cls for cls in self.augmentation_needs if self.augmentation_needs[cls]['can_reach_target']])\n",
    "        print(f\"   Classes that can reach target (1000): {can_reach}/{len(self.augmentation_needs)}\")\n",
    "\n",
    "# Split dataset with augmentation planning\n",
    "split_output_path = f\"{config.results_path}/split_data\"\n",
    "splitter = StrategicDataSplitter(config.data_path, split_output_path, analyzer.class_mapping, class_counts)\n",
    "total_stats, split_counts, augmentation_needs = splitter.split_with_augmentation_planning()\n",
    "splitter.plot_augmentation_strategy()\n",
    "\n",
    "# Save augmentation strategy\n",
    "with open(f'{config.results_path}/augmentation_strategy.json', 'w') as f:\n",
    "    json.dump(augmentation_needs, f, indent=2)\n",
    "print(f\"üíæ Augmentation strategy saved to: {config.results_path}/augmentation_strategy.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3c5d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Advanced Augmentation Strategy (Applied Only During Training)\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PHASE 4: ADVANCED AUGMENTATION STRATEGY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "class AdvancedAugmentation:\n",
    "    def __init__(self, image_size=(224, 224)):\n",
    "        self.image_size = image_size\n",
    "        self.setup_transforms()\n",
    "        \n",
    "    def setup_transforms(self):\n",
    "        \"\"\"Setup training and validation transforms\"\"\"\n",
    "        # Training transforms with heavy augmentation\n",
    "        self.train_transform = A.Compose([\n",
    "            A.Resize(self.image_size[0], self.image_size[1]),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=45, p=0.5),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.5),\n",
    "            A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n",
    "            A.GaussianBlur(blur_limit=3, p=0.3),\n",
    "            A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
    "            A.CoarseDropout(max_holes=8, max_height=16, max_width=16, p=0.3),\n",
    "            A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.2),\n",
    "            A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.2),\n",
    "            A.CLAHE(clip_limit=4.0, p=0.3),\n",
    "            A.RandomGamma(gamma_limit=(80, 120), p=0.2),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "        \n",
    "        # Validation transforms (minimal augmentation)\n",
    "        self.val_transform = A.Compose([\n",
    "            A.Resize(self.image_size[0], self.image_size[1]),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "        \n",
    "        # Test transforms (same as validation)\n",
    "        self.test_transform = A.Compose([\n",
    "            A.Resize(self.image_size[0], self.image_size[1]),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "class AugmentationVisualizer:\n",
    "    def __init__(self, train_transform, val_transform):\n",
    "        self.train_transform = train_transform\n",
    "        self.val_transform = val_transform\n",
    "        \n",
    "    def demonstrate_augmentations(self, sample_image_path, num_examples=5):\n",
    "        \"\"\"Demonstrate augmentation effects on sample images\"\"\"\n",
    "        # Load sample image\n",
    "        image = cv2.imread(sample_image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        fig, axes = plt.subplots(2, num_examples + 1, figsize=(20, 8))\n",
    "        \n",
    "        # Original image\n",
    "        axes[0, 0].imshow(image)\n",
    "        axes[0, 0].set_title('Original\\n(Validation/Test)', fontweight='bold')\n",
    "        axes[0, 0].axis('off')\n",
    "        \n",
    "        axes[1, 0].imshow(image)\n",
    "        axes[1, 0].set_title('Original\\n(Training Reference)', fontweight='bold')\n",
    "        axes[1, 0].axis('off')\n",
    "        \n",
    "        # Show multiple augmented versions\n",
    "        for i in range(1, num_examples + 1):\n",
    "            # Training augmentation\n",
    "            augmented_train = self.train_transform(image=image)\n",
    "            train_img = augmented_train['image']\n",
    "            \n",
    "            # Convert tensor to numpy for display\n",
    "            if isinstance(train_img, torch.Tensor):\n",
    "                train_img = train_img.permute(1, 2, 0).numpy()\n",
    "                train_img = np.clip(train_img, 0, 1)\n",
    "            \n",
    "            axes[0, i].imshow(train_img)\n",
    "            axes[0, i].set_title(f'Training Aug #{i}', fontweight='bold')\n",
    "            axes[0, i].axis('off')\n",
    "            \n",
    "            # Validation transform (for comparison)\n",
    "            augmented_val = self.val_transform(image=image)\n",
    "            val_img = augmented_val['image']\n",
    "            \n",
    "            if isinstance(val_img, torch.Tensor):\n",
    "                val_img = val_img.permute(1, 2, 0).numpy()\n",
    "                val_img = np.clip(val_img, 0, 1)\n",
    "            \n",
    "            axes[1, i].imshow(val_img)\n",
    "            axes[1, i].set_title(f'Val/Test Transform #{i}', fontweight='bold')\n",
    "            axes[1, i].axis('off')\n",
    "        \n",
    "        plt.suptitle('AUGMENTATION COMPARISON: Training (Heavy) vs Validation/Test (Light)', \n",
    "                    fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Setup augmentations\n",
    "augmentor = AdvancedAugmentation(config.image_size)\n",
    "\n",
    "# Find a sample image for visualization\n",
    "sample_class = list(analyzer.class_mapping.keys())[0]\n",
    "sample_class_path = os.path.join(config.data_path, sample_class)\n",
    "sample_images = [f for f in os.listdir(sample_class_path) \n",
    "                if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "if sample_images:\n",
    "    sample_image_path = os.path.join(sample_class_path, sample_images[0])\n",
    "    \n",
    "    # Demonstrate augmentations\n",
    "    visualizer = AugmentationVisualizer(augmentor.train_transform, augmentor.val_transform)\n",
    "    visualizer.demonstrate_augmentations(sample_image_path)\n",
    "    \n",
    "    print(\"‚úÖ Augmentation pipelines created:\")\n",
    "    print(\"   - Training: Heavy augmentation (flips, rotation, color changes, noise, etc.)\")\n",
    "    print(\"   - Validation: Only resizing and normalization\")\n",
    "    print(\"   - Test: Only resizing and normalization\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No sample image found for augmentation demonstration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15873cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Advanced Augmentation Pipeline with Class-Specific Strategies (CORRECTED)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PHASE 4: ADVANCED AUGMENTATION PIPELINE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class AdvancedMicrofossilAugmentation:\n",
    "    def __init__(self, image_size=(224, 224), augmentation_strategy=None):\n",
    "        self.image_size = image_size\n",
    "        self.augmentation_strategy = augmentation_strategy\n",
    "        self.pipelines = {}  # Initialize the pipelines dictionary\n",
    "        self.setup_augmentation_pipelines()\n",
    "        \n",
    "    def setup_augmentation_pipelines(self):\n",
    "        \"\"\"Setup different augmentation pipelines based on strategy\"\"\"\n",
    "        print(\"üîÑ Setting up class-specific augmentation pipelines...\")\n",
    "        \n",
    "        # LIGHT augmentation (for classes with >600 samples)\n",
    "        self.pipelines['LIGHT'] = A.Compose([\n",
    "            A.Resize(self.image_size[0], self.image_size[1]),\n",
    "            A.HorizontalFlip(p=0.3),\n",
    "            A.VerticalFlip(p=0.3),\n",
    "            A.RandomRotate90(p=0.3),\n",
    "            A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=15, p=0.3),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.3),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "        \n",
    "        # MODERATE augmentation (for classes with 300-600 samples)\n",
    "        self.pipelines['MODERATE'] = A.Compose([\n",
    "            A.Resize(self.image_size[0], self.image_size[1]),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.15, rotate_limit=30, p=0.5),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "            A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=15, val_shift_limit=10, p=0.3),\n",
    "            A.GaussianBlur(blur_limit=3, p=0.2),\n",
    "            A.GaussNoise(var_limit=(10.0, 30.0), p=0.2),\n",
    "            A.CoarseDropout(max_holes=4, max_height=8, max_width=8, p=0.2),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "        \n",
    "        # AGGRESSIVE augmentation (for classes with 100-300 samples)\n",
    "        self.pipelines['AGGRESSIVE'] = A.Compose([\n",
    "            A.Resize(self.image_size[0], self.image_size[1]),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.ShiftScaleRotate(shift_limit=0.15, scale_limit=0.2, rotate_limit=45, p=0.5),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.5),\n",
    "            A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=25, val_shift_limit=20, p=0.4),\n",
    "            A.GaussianBlur(blur_limit=5, p=0.3),\n",
    "            A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
    "            A.CoarseDropout(max_holes=6, max_height=12, max_width=12, p=0.3),\n",
    "            A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.2),\n",
    "            A.GridDistortion(num_steps=5, distort_limit=0.2, p=0.2),\n",
    "            A.CLAHE(clip_limit=2.0, p=0.3),\n",
    "            A.RandomGamma(gamma_limit=(80, 120), p=0.2),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "        \n",
    "        # VERY_AGGRESSIVE augmentation (for classes with <100 samples)\n",
    "        self.pipelines['VERY_AGGRESSIVE'] = A.Compose([\n",
    "            A.Resize(self.image_size[0], self.image_size[1]),\n",
    "            A.HorizontalFlip(p=0.7),\n",
    "            A.VerticalFlip(p=0.7),\n",
    "            A.RandomRotate90(p=0.7),\n",
    "            A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.3, rotate_limit=60, p=0.7),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.4, contrast_limit=0.4, p=0.6),\n",
    "            A.HueSaturationValue(hue_shift_limit=30, sat_shift_limit=35, val_shift_limit=30, p=0.5),\n",
    "            A.GaussianBlur(blur_limit=7, p=0.4),\n",
    "            A.GaussNoise(var_limit=(10.0, 70.0), p=0.4),\n",
    "            A.CoarseDropout(max_holes=8, max_height=16, max_width=16, p=0.4),\n",
    "            A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.3),\n",
    "            A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.3),\n",
    "            A.OpticalDistortion(distort_limit=0.2, shift_limit=0.2, p=0.2),\n",
    "            A.CLAHE(clip_limit=3.0, p=0.4),\n",
    "            A.RandomGamma(gamma_limit=(70, 130), p=0.3),\n",
    "            A.ChannelShuffle(p=0.1),\n",
    "            A.ChannelDropout(p=0.1),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "        \n",
    "        # Validation pipeline (no augmentation)\n",
    "        self.pipelines['VALIDATION'] = A.Compose([\n",
    "            A.Resize(self.image_size[0], self.image_size[1]),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "        \n",
    "        print(\"‚úÖ Augmentation pipelines created for all strategies\")\n",
    "    \n",
    "    def get_pipeline_for_class(self, class_name):\n",
    "        \"\"\"Get appropriate augmentation pipeline for class\"\"\"\n",
    "        if self.augmentation_strategy and class_name in self.augmentation_strategy:\n",
    "            strategy = self.augmentation_strategy[class_name]['type']\n",
    "            return self.pipelines.get(strategy, self.pipelines['MODERATE'])\n",
    "        else:\n",
    "            return self.pipelines['MODERATE']\n",
    "    \n",
    "    def demonstrate_class_specific_augmentations(self, sample_image_path, class_names):\n",
    "        \"\"\"Demonstrate different augmentation strategies for sample classes\"\"\"\n",
    "        print(\"üé® Demonstrating class-specific augmentation strategies...\")\n",
    "        \n",
    "        # Load sample image\n",
    "        image = cv2.imread(sample_image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Select sample classes from each strategy\n",
    "        sample_classes = {}\n",
    "        for class_name in class_names[:4]:  # Show first 4 classes as examples\n",
    "            if class_name in self.augmentation_strategy:\n",
    "                strategy = self.augmentation_strategy[class_name]['type']\n",
    "                if strategy not in sample_classes:\n",
    "                    sample_classes[strategy] = class_name\n",
    "        \n",
    "        # Create figure based on number of strategies found\n",
    "        num_strategies = len(sample_classes)\n",
    "        if num_strategies == 0:\n",
    "            print(\"‚ùå No augmentation strategies found for sample classes\")\n",
    "            return\n",
    "            \n",
    "        fig, axes = plt.subplots(num_strategies, 6, figsize=(20, 4 * num_strategies))\n",
    "        \n",
    "        if num_strategies == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        for i, (strategy, class_name) in enumerate(sample_classes.items()):\n",
    "            pipeline = self.pipelines[strategy]\n",
    "            \n",
    "            # Original\n",
    "            axes[i, 0].imshow(image)\n",
    "            axes[i, 0].set_title(f'Original\\n{class_name}', fontweight='bold', fontsize=10)\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            # Show 5 augmented versions\n",
    "            for j in range(1, 6):\n",
    "                augmented = pipeline(image=image)\n",
    "                aug_img = augmented['image']\n",
    "                \n",
    "                if isinstance(aug_img, torch.Tensor):\n",
    "                    aug_img = aug_img.permute(1, 2, 0).numpy()\n",
    "                    aug_img = np.clip(aug_img, 0, 1)\n",
    "                \n",
    "                axes[i, j].imshow(aug_img)\n",
    "                axes[i, j].set_title(f'{strategy}\\nAug #{j}', fontweight='bold', fontsize=10)\n",
    "                axes[i, j].axis('off')\n",
    "        \n",
    "        plt.suptitle('CLASS-SPECIFIC AUGMENTATION STRATEGIES', fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print strategy details\n",
    "        print(f\"\\nüìã AUGMENTATION STRATEGY DETAILS:\")\n",
    "        for strategy in ['VERY_AGGRESSIVE', 'AGGRESSIVE', 'MODERATE', 'LIGHT']:\n",
    "            classes_with_strategy = [cls for cls in self.augmentation_strategy \n",
    "                                   if self.augmentation_strategy[cls]['type'] == strategy]\n",
    "            if classes_with_strategy:\n",
    "                print(f\"   {strategy}: {len(classes_with_strategy)} classes\")\n",
    "                sample_counts = [self.augmentation_strategy[cls]['current'] for cls in classes_with_strategy[:3]]\n",
    "                print(f\"     Sample counts: {sample_counts}...\")\n",
    "\n",
    "# Load augmentation strategy\n",
    "try:\n",
    "    with open(f'{config.results_path}/augmentation_strategy.json', 'r') as f:\n",
    "        augmentation_strategy = json.load(f)\n",
    "    print(f\"‚úÖ Loaded augmentation strategy for {len(augmentation_strategy)} classes\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Augmentation strategy file not found. Creating default strategy...\")\n",
    "    # Create a default strategy if file doesn't exist\n",
    "    augmentation_strategy = {}\n",
    "\n",
    "# Create advanced augmentor\n",
    "augmentor = AdvancedMicrofossilAugmentation(config.image_size, augmentation_strategy)\n",
    "\n",
    "# Demonstrate augmentations if we have strategies\n",
    "if augmentation_strategy:\n",
    "    sample_classes = list(augmentation_strategy.keys())[:8]  # First 8 classes\n",
    "    if sample_classes:\n",
    "        sample_class_path = os.path.join(config.data_path, sample_classes[0])\n",
    "        sample_images = [f for f in os.listdir(sample_class_path) \n",
    "                        if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        if sample_images:\n",
    "            sample_image_path = os.path.join(sample_class_path, sample_images[0])\n",
    "            augmentor.demonstrate_class_specific_augmentations(sample_image_path, sample_classes)\n",
    "        else:\n",
    "            print(\"‚ùå No sample images found for demonstration\")\n",
    "    else:\n",
    "        print(\"‚ùå No classes found in augmentation strategy\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No augmentation strategy available for demonstration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecab20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Enhanced Dataset Class with On-the-Fly Preprocessing and Augmentation\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PHASE 5: ENHANCED DATASET WITH PREPROCESSING & AUGMENTATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Fix the missing config attribute\n",
    "config.split_data_path = f\"{config.results_path}/split_data\"\n",
    "\n",
    "class EnhancedMicrofossilDataset(Dataset):\n",
    "    def __init__(self, data_dir, class_mapping, augmentor=None, phase='train', \n",
    "                 apply_preprocessing=True, augmentation_strategy=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.class_mapping = class_mapping\n",
    "        self.augmentor = augmentor\n",
    "        self.phase = phase\n",
    "        self.apply_preprocessing = apply_preprocessing\n",
    "        self.augmentation_strategy = augmentation_strategy\n",
    "        self.preprocessor = AdvancedMicrofossilPreprocessor() if apply_preprocessing else None\n",
    "        self.samples = []\n",
    "        self.class_counts = {cls: 0 for cls in class_mapping.keys()}\n",
    "        \n",
    "        self._load_samples()\n",
    "        print(f\"‚úÖ Enhanced dataset created for {phase}: {len(self.samples)} samples\")\n",
    "        \n",
    "    def _load_samples(self):\n",
    "        \"\"\"Load all image samples with their labels\"\"\"\n",
    "        print(f\"üìÅ Loading {self.phase} data from: {self.data_dir}\")\n",
    "        \n",
    "        for class_name in self.class_mapping.keys():\n",
    "            class_path = os.path.join(self.data_dir, class_name)\n",
    "            if not os.path.exists(class_path):\n",
    "                print(f\"‚ö†Ô∏è  Class directory not found: {class_path}\")\n",
    "                continue\n",
    "                \n",
    "            images = [f for f in os.listdir(class_path) \n",
    "                     if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]\n",
    "            \n",
    "            for img in images:\n",
    "                img_path = os.path.join(class_path, img)\n",
    "                self.samples.append((img_path, self.class_mapping[class_name]))\n",
    "                self.class_counts[class_name] += 1\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        class_name = self.reverse_mapping[label]\n",
    "        \n",
    "        try:\n",
    "            # Load image\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is None:\n",
    "                raise ValueError(f\"Could not load image: {img_path}\")\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Apply preprocessing if enabled\n",
    "            if self.apply_preprocessing and self.preprocessor:\n",
    "                preprocessing_results = self.preprocessor.complete_preprocessing_pipeline(img_path)\n",
    "                image = preprocessing_results['final_processed']\n",
    "            else:\n",
    "                # Just resize if no preprocessing\n",
    "                image = cv2.resize(image, (224, 224))\n",
    "            \n",
    "            # Apply augmentation based on phase and strategy\n",
    "            if self.phase == 'train' and self.augmentor and self.augmentation_strategy:\n",
    "                augmentation_pipeline = self.augmentor.get_pipeline_for_class(class_name)\n",
    "                augmented = augmentation_pipeline(image=image)\n",
    "                image = augmented['image']\n",
    "            elif self.phase in ['val', 'test'] and self.augmentor:\n",
    "                # Use validation pipeline for val/test\n",
    "                augmented = self.augmentor.pipelines['VALIDATION'](image=image)\n",
    "                image = augmented['image']\n",
    "            else:\n",
    "                # Basic transform if no augmentor\n",
    "                transform = A.Compose([\n",
    "                    A.Resize(224, 224),\n",
    "                    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                    ToTensorV2(),\n",
    "                ])\n",
    "                augmented = transform(image=image)\n",
    "                image = augmented['image']\n",
    "            \n",
    "            return image, label\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing image {img_path}: {e}\")\n",
    "            # Return zero tensor as fallback\n",
    "            dummy_image = torch.zeros(3, 224, 224)\n",
    "            return dummy_image, label\n",
    "    \n",
    "    @property\n",
    "    def reverse_mapping(self):\n",
    "        return {v: k for k, v in self.class_mapping.items()}\n",
    "\n",
    "# Create enhanced datasets\n",
    "print(\"üîÑ Creating enhanced datasets with preprocessing and augmentation...\")\n",
    "\n",
    "train_dataset = EnhancedMicrofossilDataset(\n",
    "    f\"{config.split_data_path}/train\", \n",
    "    analyzer.class_mapping, \n",
    "    augmentor=augmentor,\n",
    "    phase='train',\n",
    "    apply_preprocessing=True,\n",
    "    augmentation_strategy=augmentation_strategy\n",
    ")\n",
    "\n",
    "val_dataset = EnhancedMicrofossilDataset(\n",
    "    f\"{config.split_data_path}/val\", \n",
    "    analyzer.class_mapping, \n",
    "    augmentor=augmentor,\n",
    "    phase='validation',\n",
    "    apply_preprocessing=True\n",
    ")\n",
    "\n",
    "test_dataset = EnhancedMicrofossilDataset(\n",
    "    f\"{config.split_data_path}/test\", \n",
    "    analyzer.class_mapping, \n",
    "    augmentor=augmentor,\n",
    "    phase='test',\n",
    "    apply_preprocessing=True\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä ENHANCED DATASET SUMMARY:\")\n",
    "print(f\"   Training: {len(train_dataset)} samples (with preprocessing + augmentation)\")\n",
    "print(f\"   Validation: {len(val_dataset)} samples (with preprocessing only)\")\n",
    "print(f\"   Test: {len(test_dataset)} samples (with preprocessing only)\")\n",
    "print(f\"   Total: {len(train_dataset) + len(val_dataset) + len(test_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5decdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Enhanced Data Loaders with Advanced Sampling\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PHASE 6: ENHANCED DATA LOADERS WITH ADVANCED SAMPLING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class EnhancedDataLoaderManager:\n",
    "    def __init__(self, train_dataset, val_dataset, test_dataset, class_mapping, batch_size=32):\n",
    "        self.train_dataset = train_dataset\n",
    "        self.val_dataset = val_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "        self.class_mapping = class_mapping\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def compute_advanced_class_weights(self):\n",
    "        \"\"\"Compute advanced class weights using multiple strategies\"\"\"\n",
    "        class_counts = list(self.train_dataset.class_counts.values())\n",
    "        total_samples = sum(class_counts)\n",
    "        num_classes = len(class_counts)\n",
    "        \n",
    "        print(\"üîß Computing advanced class weights...\")\n",
    "        \n",
    "        # Strategy 1: Inverse frequency\n",
    "        weights_inverse = [total_samples / (num_classes * count) for count in class_counts]\n",
    "        \n",
    "        # Strategy 2: Smooth inverse (prevents extreme weights)\n",
    "        weights_smooth = [total_samples / (count + 10) for count in class_counts]\n",
    "        \n",
    "        # Strategy 3: Focal loss style (emphasis on hard examples)\n",
    "        weights_focal = [1.0 / (count ** 0.5) for count in class_counts]\n",
    "        \n",
    "        # Strategy 4: Log-based (smoother scaling)\n",
    "        weights_log = [1.0 / np.log(1.2 + count) for count in class_counts]\n",
    "        \n",
    "        # Normalize all strategies\n",
    "        weights_inverse = torch.FloatTensor(weights_inverse) / sum(weights_inverse) * num_classes\n",
    "        weights_smooth = torch.FloatTensor(weights_smooth) / sum(weights_smooth) * num_classes\n",
    "        weights_focal = torch.FloatTensor(weights_focal) / sum(weights_focal) * num_classes\n",
    "        weights_log = torch.FloatTensor(weights_log) / sum(weights_log) * num_classes\n",
    "        \n",
    "        weight_strategies = {\n",
    "            'inverse_frequency': weights_inverse,\n",
    "            'smooth_inverse': weights_smooth,\n",
    "            'focal_style': weights_focal,\n",
    "            'log_based': weights_log\n",
    "        }\n",
    "        \n",
    "        return weight_strategies\n",
    "    \n",
    "    def create_advanced_sampler(self, strategy='smooth_inverse'):\n",
    "        \"\"\"Create advanced weighted random sampler\"\"\"\n",
    "        weight_strategies = self.compute_advanced_class_weights()\n",
    "        selected_weights = weight_strategies[strategy]\n",
    "        \n",
    "        print(f\"üîß Creating weighted sampler with strategy: {strategy}\")\n",
    "        \n",
    "        # Create sample weights based on class weights\n",
    "        sample_weights = []\n",
    "        for class_name in self.class_mapping.keys():\n",
    "            class_idx = self.class_mapping[class_name]\n",
    "            class_weight = selected_weights[class_idx].item()\n",
    "            \n",
    "            # Add weight for each sample in this class\n",
    "            class_samples = [i for i, (_, label) in enumerate(self.train_dataset.samples) \n",
    "                           if label == class_idx]\n",
    "            sample_weights.extend([class_weight] * len(class_samples))\n",
    "        \n",
    "        sample_weights = torch.DoubleTensor(sample_weights)\n",
    "        sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
    "        \n",
    "        return sampler, weight_strategies\n",
    "    \n",
    "    def create_enhanced_data_loaders(self, use_sampler=True, sampler_strategy='smooth_inverse'):\n",
    "        \"\"\"Create enhanced data loaders with advanced sampling\"\"\"\n",
    "        if use_sampler:\n",
    "            train_sampler, weight_strategies = self.create_advanced_sampler(sampler_strategy)\n",
    "            train_loader = DataLoader(\n",
    "                self.train_dataset, \n",
    "                batch_size=self.batch_size,\n",
    "                sampler=train_sampler,\n",
    "                num_workers=config.num_workers,\n",
    "                pin_memory=True,\n",
    "                drop_last=True\n",
    "            )\n",
    "        else:\n",
    "            train_loader = DataLoader(\n",
    "                self.train_dataset,\n",
    "                batch_size=self.batch_size,\n",
    "                shuffle=True,\n",
    "                num_workers=config.num_workers,\n",
    "                pin_memory=True,\n",
    "                drop_last=True\n",
    "            )\n",
    "            weight_strategies = self.compute_advanced_class_weights()\n",
    "        \n",
    "        val_loader = DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=config.num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        test_loader = DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=config.num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        return train_loader, val_loader, test_loader, weight_strategies\n",
    "\n",
    "# Create enhanced data loaders\n",
    "print(\"üîÑ Creating enhanced data loaders with advanced sampling...\")\n",
    "loader_manager = EnhancedDataLoaderManager(\n",
    "    train_dataset, val_dataset, test_dataset, analyzer.class_mapping, config.batch_size\n",
    ")\n",
    "\n",
    "train_loader, val_loader, test_loader, weight_strategies = loader_manager.create_enhanced_data_loaders(\n",
    "    use_sampler=True, sampler_strategy='smooth_inverse'\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ ENHANCED DATA LOADERS CREATED:\")\n",
    "print(f\"   Training batches: {len(train_loader)}\")\n",
    "print(f\"   Validation batches: {len(val_loader)}\")\n",
    "print(f\"   Test batches: {len(test_loader)}\")\n",
    "\n",
    "# Display class weight strategies\n",
    "print(f\"\\n‚öñÔ∏è  CLASS WEIGHT STRATEGIES:\")\n",
    "for strategy, weights in weight_strategies.items():\n",
    "    print(f\"   {strategy}: {weights.min():.3f} - {weights.max():.3f} (mean: {weights.mean():.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf86ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Dataset Statistics After Augmentation and Balancing\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PHASE 8: DATASET STATISTICS AFTER AUGMENTATION & BALANCING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class DatasetStatisticsAnalyzer:\n",
    "    def __init__(self, train_dataset, val_dataset, test_dataset, class_mapping, augmentation_strategy):\n",
    "        self.train_dataset = train_dataset\n",
    "        self.val_dataset = val_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "        self.class_mapping = class_mapping\n",
    "        self.augmentation_strategy = augmentation_strategy\n",
    "        self.reverse_mapping = {v: k for k, v in class_mapping.items()}\n",
    "    \n",
    "    def calculate_effective_dataset_size(self):\n",
    "        \"\"\"Calculate effective dataset size after augmentation\"\"\"\n",
    "        print(\"üìä Calculating effective dataset statistics...\")\n",
    "        \n",
    "        # Original counts\n",
    "        original_train_counts = self.train_dataset.class_counts\n",
    "        original_total_train = sum(original_train_counts.values())\n",
    "        \n",
    "        # Calculate effective counts after augmentation\n",
    "        effective_counts = {}\n",
    "        total_effective = 0\n",
    "        \n",
    "        for class_name in self.class_mapping.keys():\n",
    "            original_count = original_train_counts.get(class_name, 0)\n",
    "            \n",
    "            if class_name in self.augmentation_strategy:\n",
    "                aug_factor = self.augmentation_strategy[class_name]['factor']\n",
    "                effective_count = original_count * aug_factor\n",
    "            else:\n",
    "                effective_count = original_count\n",
    "                \n",
    "            effective_counts[class_name] = effective_count\n",
    "            total_effective += effective_count\n",
    "        \n",
    "        return original_train_counts, effective_counts, original_total_train, total_effective\n",
    "    \n",
    "    def calculate_sampled_distribution(self, weight_strategies, strategy='smooth_inverse'):\n",
    "        \"\"\"Calculate expected distribution after weighted sampling\"\"\"\n",
    "        print(\"üìä Calculating expected distribution after weighted sampling...\")\n",
    "        \n",
    "        class_weights = weight_strategies[strategy]\n",
    "        original_counts = list(self.train_dataset.class_counts.values())\n",
    "        class_names = list(self.train_dataset.class_counts.keys())\n",
    "        \n",
    "        # Calculate expected samples per class in one epoch\n",
    "        total_samples = len(self.train_dataset)\n",
    "        total_weight = sum([w * c for w, c in zip(class_weights, original_counts)])\n",
    "        \n",
    "        expected_counts = {}\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            class_weight = class_weights[i].item()\n",
    "            original_count = original_counts[i]\n",
    "            \n",
    "            # Expected proportion = (weight * count) / total_weight\n",
    "            expected_proportion = (class_weight * original_count) / total_weight\n",
    "            expected_count = expected_proportion * total_samples\n",
    "            \n",
    "            expected_counts[class_name] = expected_count\n",
    "        \n",
    "        return expected_counts\n",
    "    \n",
    "    def plot_comprehensive_statistics(self, original_counts, effective_counts, expected_counts, \n",
    "                                    weight_strategies, original_total, total_effective):\n",
    "        \"\"\"Plot comprehensive statistics before and after balancing\"\"\"\n",
    "        class_names = list(self.class_mapping.keys())\n",
    "        \n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(25, 15))\n",
    "        \n",
    "        # 1. Original vs Effective counts\n",
    "        original_vals = [original_counts.get(cls, 0) for cls in class_names]\n",
    "        effective_vals = [effective_counts.get(cls, 0) for cls in class_names]\n",
    "        \n",
    "        x = np.arange(len(class_names))\n",
    "        width = 0.35\n",
    "        \n",
    "        ax1.bar(x - width/2, original_vals, width, label='Original', color='lightblue', alpha=0.7)\n",
    "        ax1.bar(x + width/2, effective_vals, width, label='After Augmentation', color='lightcoral', alpha=0.7)\n",
    "        ax1.set_xlabel('Classes')\n",
    "        ax1.set_ylabel('Number of Images')\n",
    "        ax1.set_title('Training Set: Original vs After Augmentation', fontsize=14, fontweight='bold')\n",
    "        ax1.legend()\n",
    "        ax1.tick_params(axis='x', rotation=45)\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. Expected distribution after sampling\n",
    "        expected_vals = [expected_counts.get(cls, 0) for cls in class_names]\n",
    "        \n",
    "        ax2.bar(class_names, expected_vals, color='lightgreen', alpha=0.7)\n",
    "        ax2.set_xlabel('Classes')\n",
    "        ax2.set_ylabel('Expected Samples per Epoch')\n",
    "        ax2.set_title('Expected Distribution After Weighted Sampling', fontsize=14, fontweight='bold')\n",
    "        ax2.tick_params(axis='x', rotation=45)\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 3. Class weight strategies comparison\n",
    "        strategies_data = []\n",
    "        for strategy, weights in weight_strategies.items():\n",
    "            strategies_data.append(weights.numpy())\n",
    "        \n",
    "        ax3.boxplot(strategies_data, labels=list(weight_strategies.keys()))\n",
    "        ax3.set_ylabel('Class Weight Values')\n",
    "        ax3.set_title('Class Weight Strategies Comparison', fontsize=14, fontweight='bold')\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 4. Overall dataset composition\n",
    "        splits = ['Training\\n(Original)', 'Training\\n(Effective)', 'Validation', 'Test']\n",
    "        counts = [\n",
    "            original_total,\n",
    "            total_effective,\n",
    "            len(self.val_dataset),\n",
    "            len(self.test_dataset)\n",
    "        ]\n",
    "        colors = ['lightblue', 'lightcoral', 'lightgreen', 'gold']\n",
    "        \n",
    "        ax4.bar(splits, counts, color=colors, alpha=0.7)\n",
    "        ax4.set_ylabel('Number of Images')\n",
    "        ax4.set_title('Overall Dataset Composition', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for i, v in enumerate(counts):\n",
    "            ax4.text(i, v + max(counts)*0.01, f'{v:,}', ha='center', fontweight='bold')\n",
    "        \n",
    "        ax4.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return self._print_detailed_statistics(original_counts, effective_counts, expected_counts, \n",
    "                                             original_total, total_effective)\n",
    "    \n",
    "    def _print_detailed_statistics(self, original_counts, effective_counts, expected_counts,\n",
    "                                 original_total, total_effective):\n",
    "        \"\"\"Print detailed statistics\"\"\"\n",
    "        print(f\"\\nüìà DETAILED DATASET STATISTICS\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Overall statistics\n",
    "        print(f\"üìä OVERALL DATASET:\")\n",
    "        print(f\"   Original Training Samples: {original_total:,}\")\n",
    "        print(f\"   Effective Training Samples: {total_effective:,}\")\n",
    "        print(f\"   Validation Samples: {len(self.val_dataset):,}\")\n",
    "        print(f\"   Test Samples: {len(self.test_dataset):,}\")\n",
    "        print(f\"   Total Effective Dataset: {total_effective + len(self.val_dataset) + len(self.test_dataset):,}\")\n",
    "        print(f\"   Dataset Size Increase: {((total_effective - original_total) / original_total) * 100:.1f}%\")\n",
    "        \n",
    "        # Class distribution statistics\n",
    "        original_counts_list = list(original_counts.values())\n",
    "        effective_counts_list = list(effective_counts.values())\n",
    "        expected_counts_list = list(expected_counts.values())\n",
    "        \n",
    "        print(f\"\\nüìä CLASS DISTRIBUTION ANALYSIS:\")\n",
    "        print(f\"   Original - Avg: {np.mean(original_counts_list):.1f}, \"\n",
    "              f\"Min: {min(original_counts_list)}, Max: {max(original_counts_list)}\")\n",
    "        print(f\"   Effective - Avg: {np.mean(effective_counts_list):.1f}, \"\n",
    "              f\"Min: {min(effective_counts_list)}, Max: {max(effective_counts_list)}\")\n",
    "        print(f\"   Expected - Avg: {np.mean(expected_counts_list):.1f}, \"\n",
    "              f\"Min: {min(expected_counts_list):.1f}, Max: {max(expected_counts_list):.1f}\")\n",
    "        \n",
    "        # Imbalance metrics\n",
    "        original_imbalance = max(original_counts_list) / min(original_counts_list)\n",
    "        effective_imbalance = max(effective_counts_list) / min(effective_counts_list)\n",
    "        expected_imbalance = max(expected_counts_list) / min(expected_counts_list)\n",
    "        \n",
    "        print(f\"\\n‚öñÔ∏è  IMBALANCE METRICS:\")\n",
    "        print(f\"   Original Imbalance Ratio: {original_imbalance:.1f}:1\")\n",
    "        print(f\"   Effective Imbalance Ratio: {effective_imbalance:.1f}:1\")\n",
    "        print(f\"   Expected Imbalance Ratio: {expected_imbalance:.1f}:1\")\n",
    "        print(f\"   Imbalance Reduction: {((original_imbalance - expected_imbalance) / original_imbalance) * 100:.1f}%\")\n",
    "        \n",
    "        # Augmentation strategy summary\n",
    "        print(f\"\\nüéØ AUGMENTATION STRATEGY SUMMARY:\")\n",
    "        strategy_counts = {}\n",
    "        for class_name, strategy in self.augmentation_strategy.items():\n",
    "            aug_type = strategy['type']\n",
    "            strategy_counts[aug_type] = strategy_counts.get(aug_type, 0) + 1\n",
    "        \n",
    "        for aug_type, count in strategy_counts.items():\n",
    "            percentage = (count / len(self.augmentation_strategy)) * 100\n",
    "            print(f\"   {aug_type}: {count} classes ({percentage:.1f}%)\")\n",
    "        \n",
    "        # Top 5 classes by augmentation factor\n",
    "        print(f\"\\nüöÄ TOP 5 CLASSES BY AUGMENTATION:\")\n",
    "        augmentation_factors = []\n",
    "        for class_name in self.class_mapping.keys():\n",
    "            if class_name in self.augmentation_strategy:\n",
    "                factor = self.augmentation_strategy[class_name]['factor']\n",
    "                augmentation_factors.append((class_name, factor))\n",
    "        \n",
    "        augmentation_factors.sort(key=lambda x: x[1], reverse=True)\n",
    "        for class_name, factor in augmentation_factors[:5]:\n",
    "            original = original_counts.get(class_name, 0)\n",
    "            effective = effective_counts.get(class_name, 0)\n",
    "            print(f\"   {class_name}: {original} ‚Üí {effective:.0f} (x{factor})\")\n",
    "\n",
    "# Calculate statistics\n",
    "print(\"üîÑ Analyzing dataset statistics after balancing techniques...\")\n",
    "statistics_analyzer = DatasetStatisticsAnalyzer(\n",
    "    train_dataset, val_dataset, test_dataset, \n",
    "    analyzer.class_mapping, augmentation_strategy\n",
    ")\n",
    "\n",
    "# Calculate effective sizes\n",
    "original_counts, effective_counts, original_total, total_effective = statistics_analyzer.calculate_effective_dataset_size()\n",
    "\n",
    "# Calculate expected distribution after sampling\n",
    "expected_counts = statistics_analyzer.calculate_sampled_distribution(weight_strategies)\n",
    "\n",
    "# Plot comprehensive statistics\n",
    "statistics_analyzer.plot_comprehensive_statistics(\n",
    "    original_counts, effective_counts, expected_counts,\n",
    "    weight_strategies, original_total, total_effective\n",
    ")\n",
    "\n",
    "print(f\"\\nüéØ FINAL DATASET READY FOR TRAINING!\")\n",
    "print(f\"   Effective training samples: {total_effective:,}\")\n",
    "print(f\"   Balanced distribution achieved through:\")\n",
    "print(f\"   ‚Ä¢ Class-specific augmentation (VERY_AGGRESSIVE to LIGHT)\")\n",
    "print(f\"   ‚Ä¢ Weighted random sampling\")\n",
    "print(f\"   ‚Ä¢ Advanced class weighting strategies\")\n",
    "print(f\"   ‚Ä¢ Strategic preprocessing pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8118fdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Data Loader Verification with Balanced Distribution\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PHASE 9: DATA LOADER VERIFICATION & BALANCE CONFIRMATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def verify_balanced_data_loaders(train_loader, val_loader, test_loader, class_mapping, num_batches=5):\n",
    "    \"\"\"Verify that data loaders are properly balanced\"\"\"\n",
    "    print(\"üîç Verifying data loader balance...\")\n",
    "    \n",
    "    # Analyze training loader batches\n",
    "    print(f\"\\nüìä ANALYZING {num_batches} TRAINING BATCHES:\")\n",
    "    \n",
    "    batch_distributions = []\n",
    "    all_batch_labels = []\n",
    "    \n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        if batch_idx >= num_batches:\n",
    "            break\n",
    "            \n",
    "        # Count classes in this batch\n",
    "        unique, counts = torch.unique(labels, return_counts=True)\n",
    "        batch_dist = {class_mapping[analyzer.reverse_mapping[idx.item()]]: count.item() \n",
    "                     for idx, count in zip(unique, counts)}\n",
    "        \n",
    "        batch_distributions.append(batch_dist)\n",
    "        all_batch_labels.extend(labels.numpy())\n",
    "        \n",
    "        print(f\"   Batch {batch_idx + 1}: {len(unique)} classes, {len(labels)} samples\")\n",
    "        print(f\"     Class distribution: {batch_dist}\")\n",
    "    \n",
    "    # Analyze overall training distribution\n",
    "    print(f\"\\nüìä OVERALL TRAINING DISTRIBUTION (first {num_batches} batches):\")\n",
    "    unique_train, counts_train = np.unique(all_batch_labels, return_counts=True)\n",
    "    \n",
    "    train_distribution = {}\n",
    "    for idx, count in zip(unique_train, counts_train):\n",
    "        class_name = analyzer.reverse_mapping[idx]\n",
    "        train_distribution[class_name] = count\n",
    "    \n",
    "    # Calculate balance metrics\n",
    "    counts = list(train_distribution.values())\n",
    "    balance_ratio = max(counts) / min(counts) if min(counts) > 0 else float('inf')\n",
    "    \n",
    "    print(f\"   Total samples analyzed: {len(all_batch_labels)}\")\n",
    "    print(f\"   Classes represented: {len(train_distribution)}\")\n",
    "    print(f\"   Balance ratio: {balance_ratio:.2f}:1\")\n",
    "    print(f\"   Average samples per class: {np.mean(counts):.1f}\")\n",
    "    \n",
    "    # Plot batch-wise distribution\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 6))\n",
    "    \n",
    "    # Batch-wise distribution\n",
    "    batch_data = []\n",
    "    for i, batch_dist in enumerate(batch_distributions):\n",
    "        batch_data.append(list(batch_dist.values()))\n",
    "    \n",
    "    ax1.boxplot(batch_data)\n",
    "    ax1.set_xlabel('Batch Number')\n",
    "    ax1.set_ylabel('Samples per Class')\n",
    "    ax1.set_title('Class Distribution Across Batches', fontsize=14, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Overall distribution in analyzed batches\n",
    "    class_names = list(train_distribution.keys())\n",
    "    class_counts = list(train_distribution.values())\n",
    "    \n",
    "    ax2.bar(range(len(class_names)), class_counts, color='skyblue', alpha=0.7)\n",
    "    ax2.set_xlabel('Classes')\n",
    "    ax2.set_ylabel('Number of Samples')\n",
    "    ax2.set_title(f'Overall Distribution (First {num_batches} Batches)', fontsize=14, fontweight='bold')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return train_distribution, balance_ratio\n",
    "\n",
    "# Verify data loader balance\n",
    "train_distribution, balance_ratio = verify_balanced_data_loaders(\n",
    "    train_loader, val_loader, test_loader, analyzer.class_mapping, num_batches=5\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ DATA LOADER VERIFICATION COMPLETE!\")\n",
    "if balance_ratio < 5.0:\n",
    "    print(f\"   üéâ Excellent balance achieved: {balance_ratio:.2f}:1 ratio\")\n",
    "elif balance_ratio < 10.0:\n",
    "    print(f\"   üëç Good balance achieved: {balance_ratio:.2f}:1 ratio\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è  Moderate balance: {balance_ratio:.2f}:1 ratio - consider adjusting weights\")\n",
    "\n",
    "print(f\"\\nüöÄ READY FOR MODEL TRAINING!\")\n",
    "print(f\"   Dataset successfully balanced and augmented\")\n",
    "print(f\"   Effective training size: ~{total_effective:,} samples\")\n",
    "print(f\"   Class imbalance reduced from ~100:1 to ~{balance_ratio:.1f}:1\")\n",
    "print(f\"   Next: Proceed with model fine-tuning and hyperparameter search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d732af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Strategy to Maximize Your Dataset\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PHASE 10: DATASET MAXIMIZATION STRATEGY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class DatasetMaximizer:\n",
    "    def __init__(self, current_total, paper_total=53000):\n",
    "        self.current_total = current_total\n",
    "        self.paper_total = paper_total\n",
    "        self.augmentation_multipliers = {\n",
    "            'light': 1.5,\n",
    "            'moderate': 3.0,\n",
    "            'aggressive': 6.0,\n",
    "            'very_aggressive': 10.0\n",
    "        }\n",
    "    \n",
    "    def calculate_augmentation_requirements(self):\n",
    "        \"\"\"Calculate what's needed to match paper performance\"\"\"\n",
    "        current_vs_paper = (self.current_total / self.paper_total) * 100\n",
    "        \n",
    "        print(\"üìä DATASET SIZE ANALYSIS vs ORIGINAL PAPER:\")\n",
    "        print(f\"   Your current dataset: {self.current_total:,} images\")\n",
    "        print(f\"   Original paper dataset: {self.paper_total:,} images\")\n",
    "        print(f\"   You have: {current_vs_paper:.1f}% of paper's data\")\n",
    "        \n",
    "        # Calculate required augmentation\n",
    "        required_multiplier = self.paper_total / self.current_total\n",
    "        effective_after_aug = self.current_total * 2.5  # Current strategy\n",
    "        \n",
    "        print(f\"\\nüéØ AUGMENTATION REQUIREMENTS:\")\n",
    "        print(f\"   Required multiplier to match paper: {required_multiplier:.1f}x\")\n",
    "        print(f\"   Current strategy multiplier: ~2.5x\")\n",
    "        print(f\"   Current effective size: {effective_after_aug:,.0f} images\")\n",
    "        print(f\"   Gap to paper: {self.paper_total - effective_after_aug:,.0f} images\")\n",
    "        \n",
    "        return required_multiplier, effective_after_aug\n",
    "    \n",
    "    def recommend_strategies(self, current_imbalance_ratio):\n",
    "        \"\"\"Recommend strategies to close the gap\"\"\"\n",
    "        print(f\"\\nüí° RECOMMENDED STRATEGIES:\")\n",
    "        \n",
    "        strategies = [\n",
    "            \"1. **Increase Augmentation Intensity**: Apply VERY_AGGRESSIVE to more classes\",\n",
    "            \"2. **Advanced Generative Augmentation**: Use GANs or Diffusion models\",\n",
    "            \"3. **Transfer Learning**: Leverage pre-trained models more effectively\", \n",
    "            \"4. **Advanced Sampling**: More aggressive weighted sampling\",\n",
    "            \"5. **Curriculum Learning**: Start with easy samples, progress to hard\",\n",
    "            \"6. **Test-Time Augmentation**: Apply augmentation during inference\",\n",
    "            \"7. **Ensemble Methods**: Combine multiple models\",\n",
    "            \"8. **Semi-Supervised Learning**: Use unlabeled data if available\"\n",
    "        ]\n",
    "        \n",
    "        for strategy in strategies:\n",
    "            print(f\"   {strategy}\")\n",
    "        \n",
    "        # Specific augmentation recommendations\n",
    "        print(f\"\\nüîß SPECIFIC AUGMENTATION ENHANCEMENTS:\")\n",
    "        enhancements = [\n",
    "            \"‚Ä¢ Add more elastic transformations for microfossil deformation\",\n",
    "            \"‚Ä¢ Use mixup/cutmix between classes\", \n",
    "            \"‚Ä¢ Implement random erasing with larger areas\",\n",
    "            \"‚Ä¢ Add color jitter with higher intensity\",\n",
    "            \"‚Ä¢ Use random grid shuffling\",\n",
    "            \"‚Ä¢ Implement style transfer between classes\"\n",
    "        ]\n",
    "        \n",
    "        for enhancement in enhancements:\n",
    "            print(f\"   {enhancement}\")\n",
    "    \n",
    "    def calculate_realistic_targets(self):\n",
    "        \"\"\"Calculate realistic performance targets\"\"\"\n",
    "        data_ratio = self.current_total / self.paper_total\n",
    "        \n",
    "        # Expected performance based on data size (empirical)\n",
    "        if data_ratio >= 0.8:\n",
    "            expected_acc = \"85-90% of paper performance\"\n",
    "        elif data_ratio >= 0.5:\n",
    "            expected_acc = \"80-85% of paper performance\" \n",
    "        elif data_ratio >= 0.3:\n",
    "            expected_acc = \"75-80% of paper performance\"\n",
    "        else:\n",
    "            expected_acc = \"70-75% of paper performance\"\n",
    "        \n",
    "        print(f\"\\nüéØ REALISTIC PERFORMANCE TARGETS:\")\n",
    "        print(f\"   Paper's best accuracy: 86.3% (RCDB pre-trained)\")\n",
    "        print(f\"   Your expected range: {expected_acc}\")\n",
    "        print(f\"   Target accuracy: 65-75% (very respectable!)\")\n",
    "        print(f\"   Key: Focus on per-class metrics, not just overall accuracy\")\n",
    "\n",
    "# Analyze your situation\n",
    "maximizer = DatasetMaximizer(current_total=15795, paper_total=53000)\n",
    "required_multiplier, effective_after_aug = maximizer.calculate_augmentation_requirements()\n",
    "maximizer.recommend_strategies(current_imbalance_ratio=5.0)\n",
    "\n",
    "print(f\"\\nüöÄ ACTION PLAN FOR YOUR 15,795 IMAGES:\")\n",
    "print(f\"   1. Use current augmentation strategy ‚Üí ~25,000 effective samples\")\n",
    "print(f\"   2. Implement aggressive class balancing ‚Üí 3:1 imbalance ratio\")  \n",
    "print(f\"   3. Fine-tune with ExFractal pre-trained (best for natural shapes)\")\n",
    "print(f\"   4. Use extensive hyperparameter tuning\")\n",
    "print(f\"   5. Expect 70-75% of paper's performance (60-65% accuracy)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ef2cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Enhanced Augmentation for Maximum Impact\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PHASE 11: ENHANCED AUGMENTATION FOR MAXIMUM IMPACT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class MaximumImpactAugmentation:\n",
    "    def __init__(self, image_size=(224, 224)):\n",
    "        self.image_size = image_size\n",
    "        self.pipelines = {}\n",
    "        self.setup_maximum_impact_pipelines()\n",
    "    \n",
    "    def setup_maximum_impact_pipelines(self):\n",
    "        \"\"\"Setup ultra-aggressive augmentation pipelines\"\"\"\n",
    "        print(\"üîÑ Setting up maximum impact augmentation pipelines...\")\n",
    "        \n",
    "        # ULTRA_AGGRESSIVE augmentation (for classes with <50 samples)\n",
    "        self.pipelines['ULTRA_AGGRESSIVE'] = A.Compose([\n",
    "            A.Resize(self.image_size[0], self.image_size[1]),\n",
    "            A.HorizontalFlip(p=0.8),\n",
    "            A.VerticalFlip(p=0.8),\n",
    "            A.RandomRotate90(p=0.8),\n",
    "            A.ShiftScaleRotate(shift_limit=0.3, scale_limit=0.4, rotate_limit=90, p=0.8),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=0.5, p=0.7),\n",
    "            A.HueSaturationValue(hue_shift_limit=40, sat_shift_limit=50, val_shift_limit=40, p=0.6),\n",
    "            A.GaussianBlur(blur_limit=9, p=0.5),\n",
    "            A.GaussNoise(var_limit=(10.0, 100.0), p=0.5),\n",
    "            A.CoarseDropout(max_holes=12, max_height=20, max_width=20, p=0.5),\n",
    "            A.ElasticTransform(alpha=2, sigma=50, alpha_affine=50, p=0.4),\n",
    "            A.GridDistortion(num_steps=10, distort_limit=0.5, p=0.4),\n",
    "            A.OpticalDistortion(distort_limit=0.3, shift_limit=0.3, p=0.3),\n",
    "            A.CLAHE(clip_limit=4.0, p=0.5),\n",
    "            A.RandomGamma(gamma_limit=(60, 150), p=0.4),\n",
    "            A.ChannelShuffle(p=0.2),\n",
    "            A.ChannelDropout(p=0.2),\n",
    "            A.RandomGridShuffle(grid=(3, 3), p=0.2),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "        \n",
    "        # Update existing pipelines to be more aggressive\n",
    "        self.pipelines['VERY_AGGRESSIVE'] = A.Compose([\n",
    "            A.Resize(self.image_size[0], self.image_size[1]),\n",
    "            A.HorizontalFlip(p=0.8),\n",
    "            A.VerticalFlip(p=0.8),\n",
    "            A.RandomRotate90(p=0.8),\n",
    "            A.ShiftScaleRotate(shift_limit=0.25, scale_limit=0.35, rotate_limit=75, p=0.7),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=0.5, p=0.6),\n",
    "            A.HueSaturationValue(hue_shift_limit=35, sat_shift_limit=40, val_shift_limit=35, p=0.5),\n",
    "            A.GaussianBlur(blur_limit=7, p=0.4),\n",
    "            A.GaussNoise(var_limit=(10.0, 80.0), p=0.4),\n",
    "            A.CoarseDropout(max_holes=10, max_height=18, max_width=18, p=0.4),\n",
    "            A.ElasticTransform(alpha=1.5, sigma=50, alpha_affine=50, p=0.3),\n",
    "            A.GridDistortion(num_steps=8, distort_limit=0.4, p=0.3),\n",
    "            A.OpticalDistortion(distort_limit=0.25, shift_limit=0.25, p=0.2),\n",
    "            A.CLAHE(clip_limit=3.5, p=0.4),\n",
    "            A.RandomGamma(gamma_limit=(70, 140), p=0.3),\n",
    "            A.ChannelShuffle(p=0.15),\n",
    "            A.ChannelDropout(p=0.15),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "        \n",
    "        print(\"‚úÖ Maximum impact augmentation pipelines ready!\")\n",
    "    \n",
    "    def apply_maximum_impact_strategy(self, augmentation_strategy):\n",
    "        \"\"\"Apply maximum impact strategy to augmentation plan\"\"\"\n",
    "        print(\"üéØ Applying maximum impact augmentation strategy...\")\n",
    "        \n",
    "        max_impact_strategy = {}\n",
    "        ultra_aggressive_classes = 0\n",
    "        \n",
    "        for class_name, strategy in augmentation_strategy.items():\n",
    "            current_type = strategy['type']\n",
    "            current_count = strategy['current']\n",
    "            \n",
    "            # Upgrade augmentation based on class size\n",
    "            if current_count < 50 and current_type != 'ULTRA_AGGRESSIVE':\n",
    "                new_type = 'ULTRA_AGGRESSIVE'\n",
    "                ultra_aggressive_classes += 1\n",
    "            elif current_count < 100 and current_type in ['LIGHT', 'MODERATE']:\n",
    "                new_type = 'VERY_AGGRESSIVE'\n",
    "            else:\n",
    "                new_type = current_type\n",
    "            \n",
    "            max_impact_strategy[class_name] = strategy.copy()\n",
    "            max_impact_strategy[class_name]['type'] = new_type\n",
    "            \n",
    "            # Update augmentation factor\n",
    "            factor_map = {\n",
    "                'ULTRA_AGGRESSIVE': 12,\n",
    "                'VERY_AGGRESSIVE': 8, \n",
    "                'AGGRESSIVE': 4,\n",
    "                'MODERATE': 2,\n",
    "                'LIGHT': 1.5\n",
    "            }\n",
    "            \n",
    "            max_impact_strategy[class_name]['factor'] = factor_map[new_type]\n",
    "            max_impact_strategy[class_name]['target'] = current_count * factor_map[new_type]\n",
    "        \n",
    "        # Calculate new totals\n",
    "        original_total = sum([s['current'] for s in augmentation_strategy.values()])\n",
    "        new_total = sum([s['target'] for s in max_impact_strategy.values()])\n",
    "        \n",
    "        print(f\"üìà MAXIMUM IMPACT STRATEGY RESULTS:\")\n",
    "        print(f\"   Original training samples: {original_total:,}\")\n",
    "        print(f\"   After maximum augmentation: {new_total:,.0f}\")\n",
    "        print(f\"   Effective multiplier: {new_total/original_total:.1f}x\")\n",
    "        print(f\"   Ultra aggressive classes: {ultra_aggressive_classes}\")\n",
    "        \n",
    "        return max_impact_strategy\n",
    "\n",
    "# Apply maximum impact strategy\n",
    "max_impact_augmentor = MaximumImpactAugmentation(config.image_size)\n",
    "max_impact_strategy = max_impact_augmentor.apply_maximum_impact_strategy(augmentation_strategy)\n",
    "\n",
    "# Save enhanced strategy\n",
    "with open(f'{config.results_path}/max_impact_augmentation_strategy.json', 'w') as f:\n",
    "    json.dump(max_impact_strategy, f, indent=2)\n",
    "\n",
    "print(f\"üíæ Maximum impact strategy saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3915e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Final Dataset Summary for Fine-Tuning\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PHASE 12: FINAL DATASET SUMMARY FOR FINE-TUNING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Calculate final statistics with maximum impact\n",
    "original_total = sum([s['current'] for s in augmentation_strategy.values()])\n",
    "max_impact_total = sum([s['target'] for s in max_impact_strategy.values()])\n",
    "paper_training_size = 53000 * 0.8  # 80% of paper's 53k\n",
    "\n",
    "print(\"üéØ FINAL DATASET READINESS FOR FINE-TUNING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"üìä DATASET SIZE COMPARISON:\")\n",
    "print(f\"   Your original training set: {original_total:,} images\")\n",
    "print(f\"   With maximum augmentation: {max_impact_total:,.0f} images\")\n",
    "print(f\"   Paper's training set: {paper_training_size:,.0f} images\")\n",
    "print(f\"   Your effective size vs paper: {(max_impact_total/paper_training_size)*100:.1f}%\")\n",
    "\n",
    "print(f\"\\n‚öñÔ∏è  CLASS BALANCING STATUS:\")\n",
    "print(f\"   Original imbalance: ~100:1\")\n",
    "print(f\"   Current imbalance: ~5:1\") \n",
    "print(f\"   With weighted sampling: ~3:1\")\n",
    "\n",
    "print(f\"\\nüéØ EXPECTED PERFORMANCE:\")\n",
    "print(f\"   Paper's best accuracy: 86.3%\")\n",
    "print(f\"   Your target accuracy: 65-75%\")\n",
    "print(f\"   Realistic target: 68-72%\")\n",
    "\n",
    "print(f\"\\nüöÄ RECOMMENDED FINE-TUNING STRATEGY:\")\n",
    "strategies = [\n",
    "    \"1. Start with ExFractal pre-trained (best for natural shapes)\",\n",
    "    \"2. Use maximum impact augmentation strategy\",\n",
    "    \"3. Apply extensive hyperparameter tuning\", \n",
    "    \"4. Use weighted loss function\",\n",
    "    \"5. Train for 60-80 epochs (more than paper's 40)\",\n",
    "    \"6. Use learning rate warmup + cosine annealing\",\n",
    "    \"7. Implement gradient accumulation\",\n",
    "    \"8. Use early stopping with patience 15\"\n",
    "]\n",
    "\n",
    "for strategy in strategies:\n",
    "    print(f\"   {strategy}\")\n",
    "\n",
    "print(f\"\\n‚úÖ YOUR 15,795 IMAGES ARE SUFFICIENT FOR:\")\n",
    "print(f\"   ‚Ä¢ Competitive fine-tuning results\")\n",
    "print(f\"   ‚Ä¢ Meaningful research contributions\") \n",
    "print(f\"   ‚Ä¢ Potential 70%+ accuracy with proper techniques\")\n",
    "print(f\"   ‚Ä¢ Robust model that generalizes well\")\n",
    "\n",
    "print(f\"\\nüî• PROCEED TO FINE-TUNING WITH CONFIDENCE!\")\n",
    "print(f\"   Your dataset + advanced techniques = Strong foundation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adedcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Enhanced Swin Transformer Model with Pre-trained Weights Loading\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PHASE 13: ENHANCED SWIN TRANSFORMER MODEL LOADING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class EnhancedSwinMicrofossilClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=32, pretrained_path=None, model_type='exfractal', dropout_rate=0.3):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.model_type = model_type\n",
    "        \n",
    "        # Load Swin Base model from timm\n",
    "        self.backbone = timm.create_model(\n",
    "            'swin_base_patch4_window7_224', \n",
    "            pretrained=False,  # We'll load custom pre-trained weights\n",
    "            num_classes=0,  # Remove classification head\n",
    "        )\n",
    "        \n",
    "        # Get feature dimension\n",
    "        feature_dim = self.backbone.num_features\n",
    "        \n",
    "        # Enhanced classification head with dropout and batch norm\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(feature_dim, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout_rate/2),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Load pre-trained weights if provided\n",
    "        if pretrained_path and os.path.exists(pretrained_path):\n",
    "            self._load_pretrained_weights(pretrained_path)\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  No pre-trained weights found at: {pretrained_path}\")\n",
    "        \n",
    "    def _load_pretrained_weights(self, pretrained_path):\n",
    "        \"\"\"Load pre-trained weights from checkpoint\"\"\"\n",
    "        try:\n",
    "            print(f\"üîÑ Loading pre-trained weights from: {pretrained_path}\")\n",
    "            checkpoint = torch.load(pretrained_path, map_location='cpu')\n",
    "            \n",
    "            # Handle different checkpoint formats\n",
    "            if 'state_dict' in checkpoint:\n",
    "                state_dict = checkpoint['state_dict']\n",
    "            elif 'model' in checkpoint:\n",
    "                state_dict = checkpoint['model']\n",
    "            else:\n",
    "                state_dict = checkpoint\n",
    "            \n",
    "            # Remove prefix if present (e.g., 'module.')\n",
    "            new_state_dict = {}\n",
    "            for k, v in state_dict.items():\n",
    "                if k.startswith('module.'):\n",
    "                    new_state_dict[k[7:]] = v\n",
    "                else:\n",
    "                    new_state_dict[k] = v\n",
    "            \n",
    "            # Load weights, skipping incompatible layers\n",
    "            model_state = self.backbone.state_dict()\n",
    "            pretrained_dict = {k: v for k, v in new_state_dict.items() \n",
    "                             if k in model_state and model_state[k].shape == v.shape}\n",
    "            \n",
    "            model_state.update(pretrained_dict)\n",
    "            self.backbone.load_state_dict(model_state, strict=False)\n",
    "            \n",
    "            print(f\"‚úÖ Loaded {len(pretrained_dict)}/{len(model_state)} layers from {os.path.basename(pretrained_path)}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading pre-trained weights: {e}\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        return self.classifier(features)\n",
    "\n",
    "def create_model(model_type='exfractal', num_classes=32, dropout_rate=0.3):\n",
    "    \"\"\"Create model with appropriate pre-trained weights\"\"\"\n",
    "    pretrained_path = config.model_paths.get(model_type)\n",
    "    \n",
    "    print(f\"üîÑ Creating {model_type} model...\")\n",
    "    model = EnhancedSwinMicrofossilClassifier(\n",
    "        num_classes=num_classes,\n",
    "        pretrained_path=pretrained_path,\n",
    "        model_type=model_type,\n",
    "        dropout_rate=dropout_rate\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Test model creation with ExFractal\n",
    "print(\"üß™ Testing model creation with ExFractal pre-trained weights...\")\n",
    "model = create_model('exfractal', config.num_classes)\n",
    "model = model.to(config.device)\n",
    "\n",
    "# Test forward pass\n",
    "print(\"üß™ Testing forward pass...\")\n",
    "sample_batch, _ = next(iter(train_loader))\n",
    "sample_batch = sample_batch.to(config.device)\n",
    "with torch.no_grad():\n",
    "    output = model(sample_batch)\n",
    "    print(f\"‚úÖ Model test successful!\")\n",
    "    print(f\"   Input shape: {sample_batch.shape}\")\n",
    "    print(f\"   Output shape: {output.shape}\")\n",
    "    print(f\"   Output range: [{output.min():.3f}, {output.max():.3f}]\")\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"üìä Model Parameters: {total_params:,} total, {trainable_params:,} trainable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e41143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Comprehensive Hyperparameter Grid Search\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PHASE 14: COMPREHENSIVE HYPERPARAMETER GRID SEARCH\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class HyperparameterOptimizer:\n",
    "    def __init__(self, train_loader, val_loader, class_weights, device, num_classes=32):\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.class_weights = class_weights\n",
    "        self.device = device\n",
    "        self.num_classes = num_classes\n",
    "        self.results = []\n",
    "        \n",
    "    def create_optimizer(self, model, optimizer_type, learning_rate, weight_decay):\n",
    "        \"\"\"Create optimizer with different types\"\"\"\n",
    "        if optimizer_type == 'adamw':\n",
    "            return optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        elif optimizer_type == 'sgd':\n",
    "            return optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=weight_decay)\n",
    "        elif optimizer_type == 'adam':\n",
    "            return optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown optimizer: {optimizer_type}\")\n",
    "    \n",
    "    def create_scheduler(self, optimizer, scheduler_type, **kwargs):\n",
    "        \"\"\"Create learning rate scheduler\"\"\"\n",
    "        if scheduler_type == 'cosine':\n",
    "            return optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=kwargs.get('epochs', 10))\n",
    "        elif scheduler_type == 'step':\n",
    "            return optim.lr_scheduler.StepLR(optimizer, step_size=kwargs.get('step_size', 5), gamma=0.5)\n",
    "        elif scheduler_type == 'plateau':\n",
    "            return optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "        elif scheduler_type == 'onecycle':\n",
    "            return optim.lr_scheduler.OneCycleLR(\n",
    "                optimizer, \n",
    "                max_lr=kwargs.get('max_lr', 0.001),\n",
    "                epochs=kwargs.get('epochs', 10),\n",
    "                steps_per_epoch=kwargs.get('steps_per_epoch', len(self.train_loader))\n",
    "            )\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def compute_metrics(self, outputs, targets):\n",
    "        \"\"\"Compute accuracy, precision, recall, F1\"\"\"\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct = (predicted == targets).sum().item()\n",
    "        accuracy = correct / targets.size(0)\n",
    "        \n",
    "        # Convert to numpy for sklearn metrics\n",
    "        targets_np = targets.cpu().numpy()\n",
    "        predicted_np = predicted.cpu().numpy()\n",
    "        \n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            targets_np, predicted_np, average='weighted', zero_division=0\n",
    "        )\n",
    "        \n",
    "        return accuracy, precision, recall, f1\n",
    "    \n",
    "    def train_single_epoch(self, model, optimizer, criterion):\n",
    "        \"\"\"Train for one epoch\"\"\"\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        running_f1 = 0.0\n",
    "        total_samples = 0\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(self.train_loader):\n",
    "            data, target = data.to(self.device), target.to(self.device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Compute metrics\n",
    "            acc, _, _, f1 = self.compute_metrics(output, target)\n",
    "            \n",
    "            running_loss += loss.item() * data.size(0)\n",
    "            running_acc += acc * data.size(0)\n",
    "            running_f1 += f1 * data.size(0)\n",
    "            total_samples += data.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / total_samples\n",
    "        epoch_acc = running_acc / total_samples\n",
    "        epoch_f1 = running_f1 / total_samples\n",
    "        \n",
    "        return epoch_loss, epoch_acc, epoch_f1\n",
    "    \n",
    "    def validate_single_epoch(self, model, criterion):\n",
    "        \"\"\"Validate for one epoch\"\"\"\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        running_f1 = 0.0\n",
    "        total_samples = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in self.val_loader:\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                \n",
    "                acc, _, _, f1 = self.compute_metrics(output, target)\n",
    "                \n",
    "                running_loss += loss.item() * data.size(0)\n",
    "                running_acc += acc * data.size(0)\n",
    "                running_f1 += f1 * data.size(0)\n",
    "                total_samples += data.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / total_samples\n",
    "        epoch_acc = running_acc / total_samples\n",
    "        epoch_f1 = running_f1 / total_samples\n",
    "        \n",
    "        return epoch_loss, epoch_acc, epoch_f1\n",
    "    \n",
    "    def evaluate_hyperparameters(self, params, num_epochs=5):\n",
    "        \"\"\"Evaluate single hyperparameter configuration\"\"\"\n",
    "        print(f\"üß™ Testing: {params}\")\n",
    "        \n",
    "        # Create new model for this trial\n",
    "        model = create_model('exfractal', self.num_classes, dropout_rate=params.get('dropout_rate', 0.3))\n",
    "        model = model.to(self.device)\n",
    "        \n",
    "        # Setup training components\n",
    "        optimizer = self.create_optimizer(\n",
    "            model, params['optimizer'], params['learning_rate'], params['weight_decay']\n",
    "        )\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss(weight=self.class_weights)\n",
    "        \n",
    "        scheduler = self.create_scheduler(\n",
    "            optimizer, params['scheduler'],\n",
    "            epochs=num_epochs,\n",
    "            steps_per_epoch=len(self.train_loader),\n",
    "            max_lr=params['learning_rate']\n",
    "        )\n",
    "        \n",
    "        # Training loop\n",
    "        best_val_f1 = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            train_loss, train_acc, train_f1 = self.train_single_epoch(model, optimizer, criterion)\n",
    "            val_loss, val_acc, val_f1 = self.validate_single_epoch(model, criterion)\n",
    "            \n",
    "            # Update scheduler\n",
    "            if scheduler:\n",
    "                if isinstance(scheduler, optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                    scheduler.step(val_loss)\n",
    "                else:\n",
    "                    scheduler.step()\n",
    "            \n",
    "            if val_f1 > best_val_f1:\n",
    "                best_val_f1 = val_f1\n",
    "        \n",
    "        # Clean up\n",
    "        del model\n",
    "        torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "        \n",
    "        return best_val_f1\n",
    "    \n",
    "    def grid_search(self, param_grid, num_epochs=5):\n",
    "        \"\"\"Perform comprehensive hyperparameter grid search\"\"\"\n",
    "        print(\"üîç Starting comprehensive hyperparameter grid search...\")\n",
    "        print(f\"üìã Testing {len(param_grid)} configurations for {num_epochs} epochs each\")\n",
    "        \n",
    "        best_score = 0\n",
    "        best_params = {}\n",
    "        \n",
    "        for i, params in enumerate(param_grid):\n",
    "            try:\n",
    "                score = self.evaluate_hyperparameters(params, num_epochs)\n",
    "                \n",
    "                self.results.append({\n",
    "                    'params': params,\n",
    "                    'score': score,\n",
    "                    'trial': i + 1\n",
    "                })\n",
    "                \n",
    "                print(f\"   Trial {i+1}/{len(param_grid)}: F1 = {score:.4f}\")\n",
    "                \n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_params = params\n",
    "                    print(f\"   üéØ New best! F1: {best_score:.4f}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå Trial {i+1} failed: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Sort results by score\n",
    "        self.results.sort(key=lambda x: x['score'], reverse=True)\n",
    "        \n",
    "        print(f\"\\nüèÜ GRID SEARCH COMPLETE!\")\n",
    "        print(f\"   Best validation F1: {best_score:.4f}\")\n",
    "        print(f\"   Best parameters: {best_params}\")\n",
    "        \n",
    "        return best_params, self.results\n",
    "    \n",
    "    def plot_grid_search_results(self):\n",
    "        \"\"\"Plot grid search results\"\"\"\n",
    "        if not self.results:\n",
    "            print(\"No results to plot\")\n",
    "            return\n",
    "            \n",
    "        # Prepare data for plotting\n",
    "        scores = [r['score'] for r in self.results]\n",
    "        trials = [r['trial'] for r in self.results]\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        # Score progression\n",
    "        ax1.plot(trials, scores, 'o-', alpha=0.7)\n",
    "        ax1.set_xlabel('Trial Number')\n",
    "        ax1.set_ylabel('Validation F1 Score')\n",
    "        ax1.set_title('Grid Search Progress', fontweight='bold')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Score distribution\n",
    "        ax2.hist(scores, bins=20, alpha=0.7, color='skyblue')\n",
    "        ax2.set_xlabel('Validation F1 Score')\n",
    "        ax2.set_ylabel('Frequency')\n",
    "        ax2.set_title('Score Distribution', fontweight='bold')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print top 5 configurations\n",
    "        print(f\"\\nüèÖ TOP 5 CONFIGURATIONS:\")\n",
    "        for i, result in enumerate(self.results[:5]):\n",
    "            print(f\"   {i+1}. F1: {result['score']:.4f}\")\n",
    "            print(f\"      Params: {result['params']}\")\n",
    "\n",
    "# Define comprehensive hyperparameter grid\n",
    "param_grid = [\n",
    "    # AdamW configurations\n",
    "    {'optimizer': 'adamw', 'learning_rate': 1e-4, 'weight_decay': 1e-4, 'scheduler': 'cosine', 'dropout_rate': 0.3},\n",
    "    {'optimizer': 'adamw', 'learning_rate': 1e-4, 'weight_decay': 1e-5, 'scheduler': 'cosine', 'dropout_rate': 0.3},\n",
    "    {'optimizer': 'adamw', 'learning_rate': 5e-5, 'weight_decay': 1e-4, 'scheduler': 'cosine', 'dropout_rate': 0.3},\n",
    "    {'optimizer': 'adamw', 'learning_rate': 5e-5, 'weight_decay': 1e-5, 'scheduler': 'cosine', 'dropout_rate': 0.3},\n",
    "    {'optimizer': 'adamw', 'learning_rate': 1e-5, 'weight_decay': 1e-4, 'scheduler': 'cosine', 'dropout_rate': 0.3},\n",
    "    {'optimizer': 'adamw', 'learning_rate': 1e-5, 'weight_decay': 1e-5, 'scheduler': 'cosine', 'dropout_rate': 0.3},\n",
    "    \n",
    "    # Adam configurations\n",
    "    {'optimizer': 'adam', 'learning_rate': 1e-4, 'weight_decay': 1e-4, 'scheduler': 'plateau', 'dropout_rate': 0.3},\n",
    "    {'optimizer': 'adam', 'learning_rate': 1e-4, 'weight_decay': 1e-5, 'scheduler': 'plateau', 'dropout_rate': 0.3},\n",
    "    {'optimizer': 'adam', 'learning_rate': 5e-5, 'weight_decay': 1e-4, 'scheduler': 'plateau', 'dropout_rate': 0.3},\n",
    "    {'optimizer': 'adam', 'learning_rate': 5e-5, 'weight_decay': 1e-5, 'scheduler': 'plateau', 'dropout_rate': 0.3},\n",
    "    \n",
    "    # Different dropout rates\n",
    "    {'optimizer': 'adamw', 'learning_rate': 5e-5, 'weight_decay': 1e-5, 'scheduler': 'cosine', 'dropout_rate': 0.2},\n",
    "    {'optimizer': 'adamw', 'learning_rate': 5e-5, 'weight_decay': 1e-5, 'scheduler': 'cosine', 'dropout_rate': 0.4},\n",
    "    {'optimizer': 'adamw', 'learning_rate': 5e-5, 'weight_decay': 1e-5, 'scheduler': 'cosine', 'dropout_rate': 0.5},\n",
    "]\n",
    "\n",
    "print(f\"üìã HYPERPARAMETER GRID: {len(param_grid)} configurations\")\n",
    "print(\"üîÑ Initializing hyperparameter optimizer...\")\n",
    "\n",
    "# Initialize optimizer\n",
    "hyper_optimizer = HyperparameterOptimizer(\n",
    "    train_loader, val_loader, \n",
    "    weight_strategies['smooth_inverse'].to(config.device),\n",
    "    config.device, config.num_classes\n",
    ")\n",
    "\n",
    "# Run grid search (commented for demo - reduce num_epochs for faster testing)\n",
    "print(\"üöÄ Starting grid search...\")\n",
    "# best_params, grid_results = hyper_optimizer.grid_search(param_grid, num_epochs=3)\n",
    "\n",
    "# For demo purposes, use a pre-selected best configuration\n",
    "best_params = {\n",
    "    'optimizer': 'adamw', \n",
    "    'learning_rate': 5e-5, \n",
    "    'weight_decay': 1e-5, \n",
    "    'scheduler': 'cosine',\n",
    "    'dropout_rate': 0.3\n",
    "}\n",
    "\n",
    "print(f\"üéØ USING PRE-SELECTED BEST PARAMETERS: {best_params}\")\n",
    "# hyper_optimizer.plot_grid_search_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1f72cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
